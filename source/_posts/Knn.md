---
title: K-Nearest Neighbor algorithm(KNN)
date: 2017-11-12 21:41:11
tags: 机器学习-原理讲解
categories: 学习心得
mathjax: true
---

> 近朱者赤，近墨者黑——《太子少傅箴》

### 什么是KNN算法

KNN算法，全称K-Nearest Neighbor algorithm，直译就是K个最近的邻居算法，一般称为K最近邻法。这是一种属于监督学习的分类算法。

其中心思想用八个字就能概括：近朱者赤，近墨者黑。和原意有稍许不同，这里的近朱者赤近墨者黑是指；虽然我不知道你是红是黑，但我只要看你离红的近还是黑的近就好了，红近则为红，黑近则为黑。

生活中我们也常常用这样的方法认识他人。比如：因为小亮爸爸是混社会的，所以他一定也不是什么好人，不许和他玩；小明天天去台球厅和混混打台球，所以他一定也是不良少年；李磊的朋友都是韩梅梅和李华这种英语课本中的人物，所以他的英文肯定也非常好。这种根据A周围人的属性，来推断A属性的思想，就是KNN算法的核心思想。用更加正式一点的表达就是：

> 给定一个训练数据集，对新的输入实例，在训练数据集中找到与该实例最邻近的K个实例，这K个实例多数属于哪类，就认为输入实例分类属于哪类。

### KNN算法的关键

KNN算法的思想非常容易理解，但若我们现在就开始上手编程实现KNN，就会遇到下面两个问题：

1. 什么叫离得近？怎么判断新来的实例和训练数据集中实例的邻近程度？
2. 所谓的K个实例，到底是几个实例？为什么是个变量而不是最近的一个？

这两个问题同样也是KNN算法的核心问题，会极大的影响KNN算法的性能。

#### 远近？距离！

描述远近？这不就是距离干的事吗？而数学上有多种距离定义，其中最常用的是欧氏距离。你可能没听说过这个名字，但是你一定用过下面这个公式：
$$
|AB|=\sqrt{(x\_1-x\_2)^2+(y\_1-y\_2)^2}
$$
高中时代这个公式叫两点间距离公式，其实就是欧氏距离公式在二维空间的形式（维度的概念在线性回归中再细说，这里就简单的理解为下标的最大值就好）。对于两个n维向量，$x=(x\_1,x\_2,...,x\_n)$,$y=(y\_1,y\_2,...,y\_n)$他们之间的欧式距离为：
$$
d(x,y)=\sqrt{(x\_1-y\_1)^2+(x\_2-y\_2)^2+...+(x\_n-y\_n)^2}
$$
还有很多种其他距离，比如曼哈顿距离、切比雪夫距离、汉明距离等，这里就不一一介绍了，只是对于距离计算的方式不同而已，有兴趣的可以自己上网查一下。

#### 为什么取K个实例？K值如何确定？

因为KNN算法的分类结果随K取值的不同会发生变化，下图简单的说明这一问题：

![图片1](http://ozaeyj71y.bkt.clouddn.com/image/jpg/KNN/%E5%9B%BE%E7%89%871.png)

红色和蓝色为已知训练集中的两个不同分类，现在来了一个新的输入，想要判断绿圆是属于红三角还是蓝方块。在K=3时，最近的3个实例中，有两个红三角，一个蓝方块，红三角比较多，所以新输入应该属于红三角。而K=5时，最近的5个实例中，有三个蓝方块，两个红三角，蓝方块比较多，所以新输入应该属于蓝方块。不同的K值使得KNN的分类结果不同了，这种不同最后会使得KNN的分类准确率也不同，所以找到一个最合适的K值是很关键的。

实际操作中，K值的确定往往使用交叉验证的方法，说白了就是试出来的。将训练集分20%的数据划分出去，作为测试集，取不同的K值记录各K值下的分类正确率，取正确率高的作为最终K值。

### KNN算法的步骤

有了上述背景，我们可以简单的写出KNN算法步骤：

1. 计算新入实例和各个训练样本的距离。
2. 找到距离最小的K个实例。
3. 统计这K个实例每个类别出现的次数。
4. 将出现频率最高的类别记为新入实例的类别。

### KNN算法的缺点

KNN算法的优点有很多，其中最明显的一点是，这个算法逻辑简单，易于理解。他的缺点也不少，主要是有下面几个：

1. 在样本数量不均衡时，KNN会偏向于数目更多的类别。举个例子，小亮的爸爸是黑社会，他有58个同班同学都是根正苗红的社会主义好青年，按照KNN算法小亮大概率被归为模范少年，但是这并不符合事实。
2. KNN算法需要进行繁重的距离计算：每来一个新的样本都要和所有样本进行一次距离计算，这在训练集很大的时候，会严重影响计算速度。
3. KNN算法需要存储所有训练样本，利用起来不方便。

### 总结

写到这里，KNN的核心思想及算法步骤已经全部讲解完毕。这是一个非常简单，理解起来很容易的算法。但是这并不是KNN的所有内容，为了解决KNN的各种缺陷，市面上有一系列的KNN改进算法，比如：通过引入权值来把距离考虑在内的；将训练集分组减小计算量的；使用KD树减少距离计算次数的。这些都属于KNN进阶版本的算法了，我将另开一篇文章对这些内容进行通俗易懂的解释。

最后，本人水平有限，机器学习也是才入门的水平，难免有谬误，欢迎大家指正。

### Reference

CAWI2016-行为识别课程2-机器学习-K最近邻分类PPT